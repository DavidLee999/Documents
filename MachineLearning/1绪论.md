# 绪论

## 简介

机器学习致力于研究如何通过计算的手段，利用体验来改善系统自身的性能。“经验”通常以“数据”的形式存在。因此，机器学习的主要内容，是关于如何在计算机上从数据中产生“*模型*”（model）的算法，即“*学习算法*”（learning algorithm)。

**NOTE**：有时候，“*模型*”指全局性结果，如一颗决策树；“*模式*”指局部性结果，如一条规则。

通常我们把学习过程看作一个在所有*假设*（hypothesis）组成的空间中进行**搜索**的过程，而**目标**是找到**与训练集匹配（fit）的假设**。

## 归纳偏好

通过学习的到的模型对应了假设空间中的一个假设。机器学习算法在学习过程中对某种类型假设的偏好，称为“*归纳偏好*”（inductive bias），或简称“*偏好*”。

任何一个有效的机器学习算法必有其归纳偏好，否则它将被假设空间中看似在训练集上“等效”的假设所迷惑而无法产生确定的学习结果。归纳偏好可以看作学习算法自身在一个可能很庞大的假设空间中对假设进行选择的启发式或“价值观”。例如，“奥卡姆剃刀”（Occam's razor）就是一种常用的基本原则。

归纳偏好对应了学习算法本身所做出的关于“什么样的模型更好“的假设。在具体的现实问题中，这个假设是否成立，即**算法的归纳偏好是否与问题本身匹配**，大多数时候直接决定了算法能否取得好的性能。

**NFL（没有免费午餐）定理**：总误差与学习算法无关或不同学习算法的期望性能相同。但NFL定理的一个重要前提是所有“问题”出现的机会相同或所有“问题”同等重要。它假设了f（期望学习的目标函数）是均匀分布的。这在现实中很难实现。它的**意义**在于：**学习算法的评价要根据具体问题**。

## 发展历程



