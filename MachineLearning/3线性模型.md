# 线性模型

## 基本形式

给定由 *d* 个属性描述的示例 x = (x~1~; x~2~; … ; x~d~), 其中 x~i~ 是 x 在第 i 个属性上的取值，线性模型(linear model) 试图学得一个通过属性的**线性组合**来进行预测的函数：
$$
f(\mathbf{x}) = \omega_1 x_1 + \omega_2 x_2 + ... + \omega_d x_d + b
$$
向量形式：
$$
f(\mathbf{x})=\mathbf{\omega}^T \cdot \mathbf{x}+b
$$
在 $\mathbf{\omega}$ 和 $b$ 学得后，模型就得以确定。

**优点**：

- 线性模型形式简单、易于建模；
- 许多功能更为强大的非线性模型 (nonlinear model) 可在线性模型的基础上，通过引入**层级结构**或**高维映射**而得；
- 由于 $\mathbf{\omega}$ 直观表达了各属性在预测中的重要性，因此线性模型有很好的可解释性(comprehensibility)。

## 线性回归

### 闭式解的方式

**定义**：给定数据集 $D=\{ (\mathbf{x_1}, y_1), (\mathbf{x_2}, y_2), …, (\mathbf{x_3}, y_3)\}$，"线性回归" (linear regression) 试图学得一个线性模型，通过对输入的特征进行**加权求和**和一个bias term 来尽可能准确地预测实值输出标记.

**NOTE**：对于离散属性，若属性值间存在*序* (order)关系，可通过连续化将其转化为连续值；若属性值间不存在序关系，假定有 k 个属性值，则通常转化为 k 维二值向量。

**目标**：$f(x_i)=\omega_ix_i+b$ 使得 $f(x_i) \approx y_i$

确定 $\omega$ 和 $b$ 的**关键**在于衡量 f(x) 和 y 之间的差别。**均方误差**是回归任务中最常用的性能度量。均方误差对应于*欧式距离*，具有很好的几何意义。基于均方误差来进行模型求解的方法称为*最小二乘法*。

设$E_{w,b}=\sum_{i=1}^{m}(y_i-\omega x_i -b)$. 将之分别对 $\omega$ 和 $b$ 求导并令等式为零即可得到结果。

> 这里$E_{w,b}$ 是关于 $\omega$ 和 $b$ 的凸函数。对区间 [a, b] 上定义的函数 f，若它对区间中任意两点 x~1~, x~2~ 均有 $f(\frac{x_1+x_2}{2}) \le \frac{f(x_1)+f(x_2)}{2}$，则称 f 为区间 [a, b] 上的**凸函数**。对于实数集上的函数，可通过**求二阶导数**来判别：若二阶导数在区间上非负，则称为凸函数；若二阶导数在区间上恒大于零则称为严格凸函数。

对于多元线性回归，设 $\hat{\mathbf{\omega}}=(\mathbf{\omega}; b)$, $\mathbf{y}=(y_1;y_2; … ; y_m)$ 而数据集表示为

$$\mathbf{X}=\begin{bmatrix} \mathbf{x}_1^T & 1 \\ \mathbf{x}_2^T & 1 \\ \vdots & \vdots \\ \mathbf{x}_m^T & 1 \end{bmatrix}$$

则有
$$
\hat \omega^*=\mathop{\arg \min}_{\hat \omega} (\mathbf{y}-\mathbf{X}\mathbf{\hat \omega})^T (\mathbf{y}-\mathbf{X}\mathbf{\hat \omega})
$$
令$E_\hat\omega=(\mathbf{y}-\mathbf{X}\mathbf{\hat \omega})^T (\mathbf{y}-\mathbf{X}\mathbf{\hat \omega})$ 并对 $\hat\omega$ 求导可得到：
$$
\frac{\partial E_\hat\omega}{\partial \hat\omega}=2\mathbf{X}^T (\mathbf{X} \hat\omega-\mathbf{y})
$$
令上式为零即可得到 $\hat\omega$ 最优解的闭式解。当$\mathbf{X}^T \mathbf{X}$为满秩矩阵，则可得
$$
\hat\omega^*=(\mathbf{X}^T \mathbf{X})^{-1}\mathbf{X}^T \mathbf{y}
$$
则线性回归的模型为
$$
f(\hat x_i)=\hat x_i^T(\mathbf{X}^T \mathbf{X})^{-1}\mathbf{X}^T \mathbf{y}
$$
对于非满秩的情况，最常见的接发则是引入正则化（regularization）项。

上式的计算复杂度为 O(n^2.4^) 到 O(n^3^). 它的**优点**是对训练集内的样本量大小（m）是线性的。只要内存能够放下，闭式解可以**高效地处理大数据集**。但对于特征多的数据（n维向量）,n*n 大小矩阵的求逆则太过费时。

### 梯度下降法

梯度下降法的**思想**就是不断**迭代调整参数使得代价函数最终达到最小**。

![屏幕快照 2018-01-15 11.34.10](../../../Downloads/屏幕快照 2018-01-15 11.34.10.png)

其中一个重要的参数就是**学习率**，它决定了迭代时的步长。*如果学习率太小，则可能收敛速度太慢；若学习率太大，则可能造成震荡*。

![屏幕快照 2018-01-15 11.40.41](../../../Downloads/屏幕快照 2018-01-15 11.40.41.png)

![屏幕快照 2018-01-15 11.40.53](../../../Downloads/屏幕快照 2018-01-15 11.40.53.png)

对于梯度下降法，有两个主要的**问题**：

- 收敛到局部最小值；
- 可能在某一处平坦的“高原”上不断地迭代而无法到达全局最小值。

![屏幕快照 2018-01-15 11.43.52](../../../Downloads/屏幕快照 2018-01-15 11.43.52.png)

对于线性回归来说，其代价函数（均方误差(MSE)）是

- 凸函数，这就意味着它**只有一个全局最小值而没有局部最小值**。
- 连续函数，即它的斜率不会突然变化。这就保证了梯度下降法可以任意逼近全局最小值。

在使用梯度下降法还需要注意的一点是**all features should have a similar scale**。

![屏幕快照 2018-01-15 11.54.20](../../../Downloads/屏幕快照 2018-01-15 11.54.20.png)

上图的左图中，feature 1 和 feature 2 具有相同的规模(scale)；而在右图中，feature 1 的规模比feature 2 小（因为在右图中，it takes a large change in $\theta_1$ to affect the cost function, which is why the bowl is elongated along the $\theta_1$ axis.

最后，梯度下降法也反映出训练一个模型就是**searching for a combination of model parameters 来最小化代价函数**。这个查找是在**模型的参数空间**中进行的：一个模型的参数越多，它的参数空间的维度就越大，而查找显然就更费时。

#### 批量梯度下降

要使用梯度下降法，需要计算**代价函数相对于每个参数$\theta_i$ 的导数**。

均方误差的**定义**为：
$$
MSE(\mathbf{X}, h_\theta)=\frac{1}{m}\sum\limits_{i=1}^m(\theta ^T\cdot x^{(i)}-y^{(i)})^2
$$
对$\theta_j$ 求导可得
$$
\frac{\partial}{\partial \theta_j}MSE(\theta)=\frac{2}{m}\sum\limits_{i=2}^m(\theta^T\cdot x^{(i)}-y^{(i)})x_j^{(i)}
$$
若我们一次性对**所有的参数**进行求导，则可得到*梯度向量*(gradient vector) $\nabla_\theta MSE(\theta)$:
$$
\nabla_\theta MSE(\theta)=\begin{pmatrix}
\frac{\partial}{\partial \theta_0}MSE(\theta) \\
\frac{\partial}{\partial \theta_1}MSE(\theta) \\
\vdots \\
\frac{\partial}{\partial \theta_n}MSE(\theta)
\end{pmatrix}
=\frac{2}{m}\mathbf{X}^T\cdot (\mathbf{X}\cdot\theta-\mathbf{y})
$$
这个式子使用了**整个数据集**。所以，当数据集很大 (m 很大) 时，批量梯度下降会很慢。

迭代时向**梯度方向的反方向**优化（$\eta$ 为学习率）：
$$
\theta^{(next\ step)}=\theta - \eta\nabla_\theta MSE(\theta)
$$
为了找到合适的学习率，我们可以使用**网格搜索**（grid search）。另一个比较好平衡计算的方法是**设定较大的迭代次数，但一旦梯度向量小于某个常量则跳出循环**。

#### 随机梯度下降

*随机梯度下降*在每次迭代过程中只选取训练集中的某一个实例利用式(8) 来计算梯度并完成更新。

**问题**：

- **震荡**：每次迭代代价函数都有可能走高或走低，**decreasing only on average**. 
- 当迭代停止时，有可能并不会停在最低点上而是在其附近。

![屏幕快照 2018-01-16 20.34.30](../../../Downloads/屏幕快照 2018-01-16 20.34.30.png)

**优点**：当代价函数不规则时，随机梯度下降会帮它**跳出局部最小值**。

**解决**：逐步减小学习率。这就是**模拟退火**算法：一开始时使用较大的迭代步长（来加快进度和跳出局部最小值），然后不断减小学习率以减小迭代步长，保证算法可以 settle at the global minimum.（用来计算学习率的函数称为*learning schedule*.）

**另一个问题**：选取数据的随机性：有些数据会被选取好几次而**有些数据从来用不到**。

**解决**：每次选取前都**对数据集进行“洗牌”**。

#### Mini-batch Gradient Descent

Mini-batch gradient descent是前两者的结合：每次选取一个**小的随机数据集**来计算梯度向量。**好处**之一就是能够充分利用GPU等硬件提供的资源来优化矩阵计算。

### 多项式回归

当简单的线性模型无法满足要求时，可以考虑**对数据集进行处理**。将数据中的每个特征的**高次项**作为**新的特征**加入到数据中。再利用这些数据来训练一个模型。

**优点**：

- 能够**拟合复杂的模型**；
- 找到**特征之间的联系**。因为 *polynomialFeatures* also adds all combinations of features up to the given degree. 利用算得的参数就可以审视数据中特征间的联系。

**缺点**：特征空间**维度爆炸**：*PolynomialFeatures(degree = n)* transforms an array containing *n* features into an array containing $\frac{(n+d)!}{d!n!}$ features.

#### 学习曲线（learning curve）

**过拟合**：模型在**训练集**上表现**优异**但在**测试集**上表现很差（**泛化能力差**）；

**欠拟合**：模型在训练集和测试集上表现都不好。

**学习曲线**：用于判断模型是欠拟合还是过拟合。将**训练集大小**作为自变量，将模型在训练集和测试集上的表现作为函数。

**实现**：划分好测试集和训练集。用不同大小的训练集（1到全部）训练模型，然后画出模型在训练集和测试集上的表现。

![屏幕快照 2018-01-20 16.18.53](../../../Downloads/屏幕快照 2018-01-20 16.18.53.png)

上图就是以RMSE为评判标准，不同大小的训练集训练出的模型在训练集和测试集上的表现。

(*训练集的错误从0 增加到一定程度就不再增加；测试集错误减少到一定程度也不再减少*。)

上图是一个**欠拟合模型**：**测试集和训练集到最终错误都很高**。

**注意**：**欠拟合不在于数据不够**，而在于所选模型的**学习能力**低下或者**所选特征**不好。

![overfitting_learning_curves_plot](../../../Downloads/overfitting_learning_curves_plot.png)

而这幅图是个**过拟合模型**：训练集和测试集的RMSE 够低，但是**二者之间有巨大的差距**。说明模型在训练集上表现很好但在测试集上表现很差。

下面这幅图就是选用了对的模型，**因为训练集和测试集的误差都足够小且差距不大**。

![learning_curves_plot](../../../Downloads/learning_curves_plot.png)

## 正则化线性回归

减轻过拟合的方法之一就是**引入正则化项**：自由度越低，模型越难以过拟合。

线性模型：**正则化会限制模型的权重**。

### 岭回归（Ridge Regression）

岭回归的对代价函数加上了一个正则化项$\alpha\sum_{i=1}^n\theta_i^2$。则

- 模型不仅要拟合数据，
- 还要**尽力减小权重向量的大小**。

**注意**：

- 正则化项只在**训练**的时候加入到代价函数中。
- $\alpha$ 由**用户定义**，来**控制正则化程度**。(为0 则为普通的线性模型。)

代价函数：
$$
J(\theta)=MSE(\theta)+\alpha\frac{1}{2}\sum\limits_{i=1}^n\theta_i^2
$$
**注意**：bias term $\theta_0$ **不参与正则化**。

令$\omega=[\theta_1, \theta_2,\ \ldots,\theta_n]$，正则化项就是$\omega$ 的**l~2~ 范数** (l~2~ norm)。

若要执行**批量梯度下降**，对式(9) 加入$\alpha\omega$ 即可。对于**随机梯度下降**，梯度为：
$$
gradient=2\mathbf{x}_i^T(\mathbf{x}_i^T\theta - y_i)+\alpha\theta_i
$$
而闭式解为：
$$
\hat\theta=(\mathbf{X^T}\mathbf{X}+\alpha\mathbf{A})^{-1}\mathbf{X}^T\mathbf{y}
$$
其中，$\mathbf{A}$ 为第一个元素为零的n*n 大小的单位矩阵。

**注意**：在进行正则化之前，必须**scale the data**（调整数据对尺度）.

### Lasso

Lasso 回归利用了模型参数向量的**l~1~ 范数**。

代价函数：
$$
J(\theta)=MSE(\theta)+\alpha\sum\limits_{i=1}^n|\theta_i|
$$
Lasso 倾向于**彻底消除**不重要特征的权重系数，它**自动**执行了**特征选择**并输出一个**稀疏模型**。

注意到Lasso 的代价函数在任意$\theta_i=0$ 处不可微。对于梯度下降，我们利用一个subgradient vector g:
$$
g(\theta, J)=\nabla_\theta MSE(\theta)+\alpha\begin{pmatrix}sign(\theta_1)\\ sign(\theta_2)\\ \vdots\\ sign(\theta_n)\end{pmatrix},\ where\ sign(\theta_i)=\begin{cases}-1,\ \theta_i<0\\ 0,\ \theta_i=0\\ +1,\ \theta_i > 0\end{cases}
$$

### Elastic Net

Elastic Net 是岭回归和Lasso 的**结合**。正则化项是模型权重系数l~1~ 范数和l~2~ 范数的**混合**且可以控制其混合率r。

代价函数：
$$
J(\theta)=MSE(\theta)+r\cdot\alpha\sum\limits_{i=1}^n|\theta_i|+\frac{1-r}{2}\alpha\sum\limits_{i=1}^n\theta_i^2
$$

### 早停

另一个避免过拟合的方法是**早停**：当**测试集**的错误率取得最小值时停止迭代。

![屏幕快照 2018-01-20 17.53.48](../../../Downloads/屏幕快照 2018-01-20 17.53.48.png)

可以在训练时对比epoch完成后的validation error 和当前最小的validation error并记录对应的模型参数。当我们确定训练足够（继续下去不会再有减小）时就可跳出训练并以validation error 最小的模型作为最佳模型。

## 对数几率回归

线性模型虽简单，却有丰富的变化。假设示例所对应的**输出标记**是在**指数尺度**上变化，那就可将输出标记的对数作为线性模型逼近的目标， 即
$$
\ln\ y=\mathbf{\omega}^T \mathbf{x}+b
$$
这就是*对数线性回归*（log-linear regression）。

更一般地，考虑单调可微函数 g，令 $y=g^{-1}(\mathbf{\omega}^T \mathbf{x} + b)$ ，即可得到**广义线性模型**（generalized linear model）。g 称为*联系函数*（link function）。

普通线性模型用于**回归**。要进行**分类**任务，则可利用广义线性模型：利用一个**单调可微**的函数将真实标记y 和线性回归模型的预测值联系起来。

考虑二分类任务，输出标记$y \in \{0, 1\}$. 而预测值z 是一个实值。则需要将实值z 转换为0/1 值。最理想的是**单位阶跃函数**。
$$
y =
\begin{cases}
0, & z < 0 \\
0.5, & z = 0 \\
1, & z > 0
\end{cases}
$$
阶跃函数不连续，不能作为$g^{-1}(\cdot)$。

需要找到一个单调可微的*替代函数*，**对数几率函数**（logistic function）正是这样一个函数。从下图可以看出，对数几率函数是一个Sigmoid函数（即S 型函数）。
$$
y =\frac{1}{1+e^{-z}}=\frac{1}{1+e^{-(\mathbf{\omega^T\mathbf{x}+b})}}
$$
![屏幕快照 2018-01-08 14.22.17](../../../Downloads/屏幕快照 2018-01-08 14.22.17.png)

将上式取对数：
$$
\ln \frac{y}{1-y}=\mathbf{\omega}^T\mathbf{x}+b
$$
*将y 视为样本作为正例的可能性，则1 - y 就是其反例的可能性。二者的比值就是几率。对它取对数就是对数几率*。

所以式(20) 是**用线性回归模型的预测结果取逼近真实标记的对数几率**，因此其对应的模型称为**对数几率回归**或**逻辑回归**。

**优点**：

- 它是对**分类可能性**进行建模，无需事先假设数据分布，避免了分布不准确带来的问题；
- 它不是仅预测出“类别”，而是得到**近似概率预测**；
- 对率函数是**任意阶可导**的**凸函数**，良好的数学性质使其可以用于许多数值优化算法。

### 求解

将式(19) 中的y 视为类后验概率估计$p(y=1\ |\ \mathbf{x})$, 就可以将式(20) 重写为
$$
\ln \frac{p(y=1|\ \mathbf{x})}{p(y=0|\ \mathbf{x})}=\mathbf{\omega}^T\mathbf{x}+b
$$
就有
$$
\begin{align}
p(y=1\ |\ \mathbf{x})=\frac{e^{\mathbf{\omega}^T\mathbf{x}+b}}{1+e^{\mathbf{\omega}^T\mathbf{x}+b}} \\
p(y=0\ |\ \mathbf{x})=\frac{1}{1+e^{\mathbf{\omega}^T\mathbf{x}+b}}
\end{align}
$$
利用**极大似然法**（maximum likelihood）来对参数进行估计。给定数据集$\{(\mathbf{x}_i,\ y_i)\}^m_{i=1}$, 对率回归模型最大化*对数似然*：
$$
l(\mathbf{\omega},b)=\sum\limits_{i=1}^m\ln p(y_i|\ \mathbf{x};\ \mathbf{\omega},b)
$$
即**令每个样本属于其真实标记的概率越大越好**。

记$\mathbf{\beta}=(\mathbf{\omega};b),\hat{\mathbf{x}}=(\mathbf{x};\ 1)$, z 就可以写成$\mathbf{\beta}^T \hat{\mathbf{x}}$. 式10 中的似然项可以写成


$$
p(y_i|\ \mathbf{x};\ \mathbf{\omega},b)=y_ip_1(\hat{\mathbf{x}}_i;\mathbf{\beta})+(1-y_i)p_0(\hat{\mathbf{x}}_i;\mathbf{\beta})
$$
将式(25) 代入式(24)，并根据式(22) 和(23) 可知，最大化式(24) 等价于最小化
$$
l(\mathbf{\beta})=\sum\limits_{i=1}^m(-y_i\mathbf{\beta}^T\hat{\mathbf{x}}_i+\ln(1+e^{\mathbf{\beta}^T \hat{\mathbf{x}}_i}))
$$
式(26) 是关于$\mathbf{\beta}$ 的高阶**可导连续凸函数**，可以根据*凸优化理论*求解。

### Training and Cost Function

$$
\hat p=h_\theta(\mathbf{x})=\sigma(\theta^T\cdot \mathbf{x}),\ \sigma(t)=\frac{1}{1+\exp(-t)}
$$

代价函数：
$$
c(\theta)=
\begin{cases}
-\log(\hat p),\ y=1,\\
-\log(1-\hat p),\ y = 0,\\
\end{cases}
$$
该函数利用了$-\log(\hat p)$ 在$\hat p$ 接近0 时数值特别大的特性。对正例来说，y = 1, 若$\hat y = 1$，则$\hat p \ge 0.5 \to 1,\ -\log(\hat p)$ 很小；若$\hat y=0$，则$\hat p < 0.5 \to 0,\ -\log(\hat p)$ 很大。

整个训练集的代价函数就是上式的平均：
$$
J(\theta)=-\frac{1}{m}\sum\limits_{i=1}^{m}[y^{(i)}\log(\hat p^{(i)})+(1-y^{(i)})\log(1-\hat p^{(i)})]
$$
该方程**没有闭式解**。但该方程是**凸函数**，所以梯度下降法一定会找到全局最小值。$J(\theta)$ 对于$\theta_j$ 的偏导数为：
$$
\frac{\partial}{\partial\theta_j}j(\theta)=\frac{1}{m}\sum\limits_{i=1}^{m}(\sigma(\theta^T\cdot\mathbf{x}^{(i)})-y^{(i)})x_j^{(i)}
$$
**解释**：对每个样本该函数（式(20)）先计算其预测误差，然后和第j 个属性值相乘。最后计算整个训练集的平均值。

对于**批量梯度下降**，
$$
\nabla_\theta J(\theta)=\frac{1}{m}\mathbf{X}\cdot(\sigma(\mathbf{X}\cdot\theta)-\mathbf{y})
$$
对于**随机梯度下降**，
$$
grad=\mathbf{x}^{(i)}\cdot(\sigma(\theta^T\cdot \mathbf{x}^{(i)})-y^{(i)})^T
$$

### Decision Boundary(决策边界)

对于*对数几率函数*，当z = 0 时其为0.5。这里就是它的**决策边界**。

![屏幕快照 2018-01-22 14.52.44](../../../Downloads/屏幕快照 2018-01-22 14.52.44.png)

![屏幕快照 2018-01-22 14.53.11](../../../Downloads/屏幕快照 2018-01-22 14.53.11.png)

注意到正负样本肯能会**穿过边界**但模型**无法给出正确的预测**。

### Softmax Regression

逻辑回归可以**直接**用于**多分类**，称为*Softmax Regression*。

**思想**：给定一个样本$\mathbf{x}$，Softmax regression 为每个类别k 计算一个分数$s_k(\mathbf{x})$。再利用Softmax function (或称为*normalized exponential*) 来计算概率。下式为类别k 的函数：
$$
s_k(\mathbf{x})=\theta^T_k\cdot\mathbf{x}
$$

$$
\hat p_k=\sigma(s(\mathbf{x}))_k=\frac{\exp(s_k(\mathbf{x}))}{\sum_{j=1}^K\exp(s_j(\mathbf{x}))}
$$

Softmax regression 将预测类别指定为概率最高，也即得分最高的类别。

#### 训练

**目标**：最大化目标类别的概率。因此，最小化如下代价函数：
$$
J(\Theta)=-\frac{1}{m}\sum\limits_{i=1}^m\sum\limits_{k=1}^K y_k^{(i)}\log(\hat p_K^{(i)})
$$
上式也称为**交叉熵**（它经常用来衡量估计类别概率和真实类别概率的匹配程度，两个概率分布p 和q 的交叉熵为$H(p,q)=-\sum_xp(x)\log q(x)$）。

**解释**：

- 正确时，$y_k^{(i)}=1$，$\hat p_k^{(i)}$ 也接近于1；此时$\log(\hat p_k^{(i)})$ 从负数轴逼近0，因此cost 很小；
- 错误时，$y_k^{(i)}=1$，而对应的$\hat p_k^{(i)}$ 接近于0；此时$-\log(\hat p_k^{(i)})$ 很大，因此cost 很大；

对代价函数求偏导为：
$$
\nabla_{\theta_k}J(\Theta)=\frac{1}{m}\sum\limits_{i=1}^m(\hat p_k^{(i)}-y_k{(i)})\mathbf{x}^{(i)}
$$

## 线性判别分析

**思想**：给定训练样例集，设法将样例投影到一条直线上，使得**同类样例的投影点尽可能接近**、 异类样例的投影点尽可能远离；在对新样本进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定新样本的类别。

![屏幕快照 2018-01-22 15.35.17](../../../Downloads/屏幕快照 2018-01-22 15.35.17.png)

具体**描述**：

给丁数据集$D=\{(\mathbf{x}_i,y_i\}^m_{i=1},\ y_i\in\{0,\ 1\}$ ，令$\mathbf{X}_ii,\ \mu_i,\ \mathbf{\Sigma}_i$ 为第i 类示例的集合、均值向量和协方差矩阵。将数据投影到直线$\omega$ 上，则两类样本的**中心**在直线上的投影为$\omega^T\mu_0$ 和$\omega^T\mu_1$，协方差为$\omega^T\mathbf{\Sigma}_0\omega$ 和$\omega^T\mathbf{\Sigma}_1\omega$。(直线是一维空间，以上四个皆为实数。)

上面思想的**代数表示**为：$\omega^T\mathbf{\Sigma}_0\omega+ \omega^T\mathbf{\Sigma}_1\omega$  尽可能小 (同类接近) 和$||\omega^T\mu_0 - \omega^T\mu_1||$ 尽可能大 (异类相远)。即最大化目标：
$$
J=\frac{||\omega^T\mu_0 - \omega^T\mu_1||_2^2}{\omega^T\mathbf{\Sigma}_0\omega+ \omega^T\mathbf{\Sigma}_1\omega}=\frac{\omega^T(\mu_0-\mu_1)(\mu_0-\mu_1)^T\omega}{\omega^T\mathbf{\Sigma}_0\omega+ \omega^T\mathbf{\Sigma}_1\omega}
$$
定义

- *类内散度矩阵* (within-class scatter matrix)：

$$
\mathbf{S}_w=\mathbf{\Sigma}_0+\mathbf{\Sigma}_1=\sum_{\mathbf{x}\in\mathbf{X}_0}(\mathbf{x}-\mu_0)(\mathbf{x}-\mu_0)^T+\sum_{\mathbf{x}\in\mathbf{X}_1}(\mathbf{x}-\mu_1)(\mathbf{x}-\mu_1)^T
$$

- *类间散度矩阵* (between-class scatter matrix)：

$$
\mathbf{S}_b=(\mu_0-\mu_1)(\mu_0-\mu_1)^T
$$

式(37) 写为：
$$
J=\frac{\omega^T\mathbf{S}_b\omega}{\omega^T\mathbf{S}_w\omega}
$$
上式也称为**广义瑞利商** (generalized Rayleigh quotient)。

### 求解

式(40) 分子分母都是关于$\omega$ 的二次项，所以**解与其长度无关，只与方向有关**。设$\omega^T\mathbf{S}_w\omega=1$，式(40) 等价于
$$
\min_\omega\ -\omega^T\mathbf{S}_b\omega\ \ s.t.\ \omega^T\mathbf{S}_w\omega=1
$$
拉格朗日乘子法：
$$
\mathbf{S}_b\omega=\lambda\mathbf{S}_w\omega
$$
**注意**到$\mathbf{S}_b\omega$ 的**方向**恒为$\mu_0-\mu_1$，可有
$$
\mathbf{S}_b\omega=\lambda(\mu_0-\mu_1)
$$
代入式(42) 可得
$$
\omega=\mathbf{S}_w^{-1}(\mu_0-\mu_1)
$$
**考虑数值求逆的稳定性**，可用**奇异值分解**来求逆。可证明，当两类数据同先验、满足高斯分布且协方差相等时， LDA可达到最优分类。

### 多分类任务

假定存在N 个类，且第i 个类示例数为m~i~。

定义：

- *类间全局散度矩阵* ($\mu$ 为**所有**示例的均值向量)：

$$
\mathbf{S}_t=\mathbf{S}_b+\mathbf{S}_w = \sum\limits_{i=1}^m(\mathbf{x}_i-\mu)(\mathbf{x}_i-\mu)^T
$$

- *类内全局散度矩阵*：

$$
\mathbf{S}_w=\sum\limits_{i=1}^N\mathbf{S}_{w_i},\mathbf{S}_{w_i}=\sum\limits_{\mathbf{x}\in\mathbf{X}_i}(\mathbf{x}_i-\mu)(\mathbf{x}_i-\mu)^T
$$

由上两式可得
$$
\mathbf{S}_b=\mathbf{S}_t - \mathbf{S}_w=\sum\limits_{i=1}^N m_i(\mu_i-\mu)(\mu_i-\mu)^T
$$
显然，多分类 LDA 有多种实现方法：使用$\mathbf{S}_b,\ \mathbf{S}_w,\ \mathbf{S}_t$ 三者中的任何两个即可。**常用**优化
$$
\max_\mathbf{W}\frac{tr(\mathbf{W}^T\mathbf{S}_b\mathbf{W})}{tr(\mathbf{W}^T\mathbf{S}_w\mathbf{W})}
$$
其中$\mathbf{W} \in R^{d\times(N-1)}$。可用广义特征值问题求解：
$$
\mathbf{S}_b\mathbf{W}=\lambda\mathbf{S}_w\mathbf{W}
$$
则$\mathbf{W}$ 的闭式解是$\mathbf{S}_w^{-1}\mathbf{S}_b$ 的N - 1 个最大广义特征值所对应的特征向量组成的矩阵。

若将 $\mathbf{W}$ 视为一个投影矩阵，则多分类 LDA 将样本投影到 N-1 维空间， N-1 通常**远小于数据原有的属性数**。于是，可通过这个投影来**减小样本点的维数**，且投影过程中使用了类别信息，因此LDA也常被视为一种经典的监督降维技术。

## 多分类学习

考虑 N 个类别 C~1~，C~2~，… ，C~N~，多分类学习的**基本思路**是**拆解法**，即将多分类任务拆为若干个二分类任务求解。

**拆分策略**

- 一对一（OvO）：将N 个类别**两两配对**，从而产生 N(N - 1) / 2 个二分类任务。测试时新样本提交给**所有**分类器，得到N(N - 1) / 2 个分类结果，最终结果通过投票产生：把被预测得最多的类别作为最终分类结果；
- 一对多（OvR）：每次将一个类的样例作为正例、**所有其他类**的样例作为反例来训练 N 个分类器.

![屏幕快照 2018-01-22 16.52.28](../../../Downloads/屏幕快照 2018-01-22 16.52.28.png)

- 多对多（MvM）：每次将若干个类作为正类，若干个其他类作为反类。OvO 和 OvR 是 MvM 的特例。MvM 的正、反类构造必须有**特殊的设计**。**常用技术**：*纠错输出码* (Error Correcting output Codes, ECOC)。**步骤**：

  - 编码：对 N 个类别做 M 次划分， 每次划分将一部分类别划为正类，一部分划为反类，形成一个二分类训练集；这样一共产生 M 个训练集，可训练出 M 个分类器；
  - 解码：:M 个分类器分别对测试样本进行预测，这些预测标记组成一个编码。将这个预测编码与每个类别各自的编码进行比较，返回其中距离最小的类别作为最终预测结果。

  对同等长度的编码，理论上来说，任意两个类别之间的编码距离越远，则**纠错能力越**强。

  ![屏幕快照 2018-01-22 16.56.52](../../../Downloads/屏幕快照 2018-01-22 16.56.52.png)

## 类别不平衡

*类别不平衡* (class-imbalance) 就是指分类任务中不同类别的训练样例数目差别很大的情况。

利用几率函数来说明，几率y / (1-y) 反映了正例可能性与反例可能性之比，逻辑回归中y 的阈值设置为0.5 恰表明分类器认为真实正、反例可能性相同。
$$
\frac{y}{1-y}>1\ \ 则为正例
$$
然而，当训练集中正、反例的数目不同时，令 m^+^ 表示正例数目， m^-^ 表示反例数目，则观测几率是m^+^ / m^-^，由于通常假设**训练集是真实样本总体的无偏采样**。观测几率就代表了真实几率。于是，只要分类器的**预测几率高于观测几率**就应判定为正例：
$$
\frac{y}{1-y}>\frac{m^+}{m^-} \ \ 则为正例
$$
但分类器依据式(50) 进行决策。因此需要对预测值进行调整：
$$
\frac{y^\prime}{1-y^\prime}=\frac{y}{1-y}\cdot\frac{m^-}{m^+}
$$
即**再缩放**或**再平衡** (rescaling) 策略。

三类做法：

1. 直接对训练集里的反类样例进行**欠采样** (undersampling) ，即去除一些反例使得正、反例数日接近，然后再进行学习；
2. 对训练集里的正类样例进行**过来样** (oversampling) ，即增加一些正例使得正、反例数目接近，然后再进行学习；
3. 直接基于原始训练集进行学习，但在用训练好的分类器进行预测时，将式(52) 嵌入到其决策过程中，称为**阔值移动** (threshold-moving)。

**NOTE**：

- 过采样法不能简单地对初始正例样本进行重复来样，否则会招致严重的**过拟合**，一般使用**插值**。
- 欠采样法若随机丢弃反例可能**丢失重要信息**；其代表性算法是利用**集成学习**机制，将反例划分为若干个集合供不同学习器使用，这样对每个学习器来看都进行了欠采样，但在全局来看却不会丢失重要信息。