# 集成学习

## 个体与集成



**集成学习** (ensemble learning) 通过构建并结合**多个学习器**来完成学习任务，有时也被称作*多分类器系统* (multi-classifier system)。集成学习通过将多个学习器进行结合，常可获得比单一学习器显著优越的**泛化性能**。

下图展示了集成学习的一般结构：先产生一组*个体学习器* (individual learner)，再用某种策略将它们**结合**起来。

![幕快照 2018-03-16 14.16.2](/Users/lipenghua/Downloads/屏幕快照 2018-03-16 14.16.25.png)

**同质集成**中的个体学习器亦称*基学习器* (base learner)，相应的学习算法称为*基学习算法* (base learning algorithm)；**异质集成**中的个体学习器由不同的学习算法生成，称为*组件学习器*。

要获得好的集成，个体学习器应该*好而不同*，即个体学习器要有一定的准确性，不能太坏，并且要有多样性，即学习器之间具有差异。

考虑二分类问题$y \in \{-1,+1\}$ 和真实标记函数f，假定基分类器的错误率为$\epsilon$，数学表示为：
$$
P(h_i(\mathbf{x}) \ne f(\mathbf{x})) = \epsilon
$$
假设集成通过简单的**投票法**结合T 个基分类器，若超过半数分类正确，则集成分类就正确：
$$
H(\mathbf{x})=sign(\sum_{i=1}^Th_i(\mathbf{x}))
$$
假设基分类器的错误率**相互独立**，有Hoeffding 不等式可得，**集成的错误率**为：
$$
P(H(\mathbf{x}) \ne f(\mathbf{x}))=\sum_{k=0}^{T/2}
\begin{pmatrix}T \\ k\end{pmatrix}
(1-\epsilon)^k \epsilon^{T-k}
\le\exp(-\frac{1}{2}T(1-2\epsilon)^2)
$$
上式表明，随着集成中个体分类器数目T 的增大，集成的错误率降指数级下降，最终趋于0.

上面的推导假设来基学习器的误差相互独立。现实中显然是不可能的。个体学习器的*准确性*和*多样性*之间是存在冲突的。**如何产生*好而不同*的个体学习器**，是集成学习研究的核心。

根据个体学习器的生成方式，集成学习方法大致可分为两大类：

- 个体学习器间存在**强依赖关系**、必须**串行生成**的**序列化方**法，代表是 Boosting；
- **个体**学习器间不存在强依赖关系、可**同时生成**的**并行化方法**，是 Bagging 和*随机森林* (Random Forest).

## Boosting

Boosting 是一族可将弱学习器提升为强学习器的算法。

**工作机制**：先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得**先前基学习器做错的训练样本在后续受到更多关注**，然后基于调整后的样本分布来训练下一个基学习器；如此重复进行，直至基学习器数目达到事先指定的值 T， 最终将这 T 个基学习器进行**加权**结合。

其典型代表为AdaBoost 算法，流程如下：

![幕快照 2018-03-16 15.04.4](/Users/lipenghua/Downloads/屏幕快照 2018-03-16 15.04.45.png)

AdaBoost 算法有多种推导，常用的是鲫鱼*加权模型* (additive model)，即基学习器的**线性组合**：
$$
H(\mathbf{x}) = \sum_{t=1}^T\alpha_t h_t(\mathbf{x})
$$
来最小化**指数损失函数** (exponential loss function)：
$$
l_{\exp}(H|D)=E_{\mathbf{x} \sim D}[e^{-f(\mathbf{x})H(\mathbf{x})}]
$$
若H 能令指数损失最小化，则考虑式(5) 对于H 的偏导：
$$
\frac{\partial l_{\exp}(H|D)}{\partial H(\mathbf{x})}=
-e^{-H({\mathbf{x}})}P(f(\mathbf{x})=1|\mathbf{x}) +e^{H(\mathbf{x})}P(f(\mathbf{x})=-1|\mathbf{x})
$$
令上式为0 可得：
$$
H(\mathbf{x}) = \frac{1}{2} \ln \frac{P(f(\mathbf{x}) = 1|\mathbf{x})}{P(f(\mathbf{x})=-1|\mathbf{x})}
$$
结合对数函数的图像，可以有：
$$
\begin{align}
sign(H(\mathbf{x})) & =sign \left(
\frac{1}{2} \ln \frac{P(f(\mathbf{x}) = 1|\mathbf{x})}{P(f(\mathbf{x})=-1|\mathbf{x})} \right) \\
 & =
 \begin{cases}
 1,\ P(f(\mathbf{x}) = 1|\mathbf{x}) > P(f(\mathbf{x})=-1|\mathbf{x}) \\
 -1,\ P(f(\mathbf{x}) = 1|\mathbf{x}) < P(f(\mathbf{x})=-1|\mathbf{x})
 \end{cases} \\
 & = \operatorname*{arg\,max}_{y \in \{-1, 1\}} P(f({\mathbf{x})=y|\mathbf{x}})
\end{align}
$$
上式表明sign(H) 达到了贝叶斯最优错误率。换言之，若指数损失函数最小化，则分类错误率也将最小化（指数损失是0/1 损失函数的一致(consistent) 替代损失函数）。

从算法图可以看到，第一个基分类器h1 是通过直接将算法应用到初始数据分布而得。此后迭代生成ht 和at。当基分类器ht 基于分布Dt 产生后，该分类器的权重at 应使得$\alpha_t h_t$ 最小化指数损失函数：
$$
\begin{align}
l_{\exp}(\alpha_t h_t|D_t) & = E_{\mathbf{x} \sim D_t}[e^{-f(\mathbf{x})\alpha_t h_t(\mathbf{x})}] \\
 & = E_{\mathbf{x} \sim D_t}[e^{-\alpha_t} \prod(f(\mathbf{x}) = h_t(\mathbf{x})) + e^{\alpha_t}\prod(f(\mathbf{x}) \ne h_t(\mathbf{x}))] \\
 & =e^{-\alpha_t}P_{\mathbf{x} \sim D_t}(f(\mathbf{x})=h_t(\mathbf{x}))+e^{\alpha_t}P_{\mathbf{x} \sim D_t}(f(\mathbf{x}) \ne h_t(\mathbf{x})) \\
 & = e^{-\alpha_t}(1-\epsilon_t) + e^{\alpha_t}\epsilon_t
\end{align}
$$
其中$\epsilon_t = P_{\mathbf{x} \sim D_t}(h_t(\mathbf{x}) \ne f(\mathbf{x}))$。对$\alpha_t$ 求偏导可得：
$$
\frac{\partial l_{\exp}(\alpha_t h_t | D_t)}{\partial \alpha_t} = -e^{-\alpha_t}(1-\epsilon_t) + e^{\alpha_t}\epsilon_t
$$
令上式为0 可得：
$$
\alpha_t = \frac{1}{2} \ln (\frac{1 - \epsilon_t}{\epsilon_t})
$$
上式即为算法中分类器权重更新公式。

AdaBoost 算法在获得$H_{t-1}$ 之后，样本分布将进行调整，使下一轮的基学习器ht 能够纠正$H_{t-1}$ 的一些错误。

**训练器要求**：理想的ht 将在分布Dt 下最小化分类误差。因此，弱分类器将基于分布Dt 来训练，且针对Dt 的分类误差应该小于0.5。

Boosting 算法要求基学习器能对特定的数据分布进行学习，这可通过**重赋权法** (re-weighting) 实施。对于无法接受带权样本的基学习算法，则可通过**重采样法** (re-sampling) 来处理，即在每一轮学习中，根据所需的分布对数据集重新进行采样。Boosting 算法在训练的每一轮都要检查当前生成的基学习器是否满足基本条件（是否比随机猜测好），若不满足，则当前基学习器被抛弃且学习过程停止。这可能导致基学习器过少而性能不佳。

从偏差 - 方差分解的角度看，Boosting 主要关注**降低偏差**。因此Boosting 能基于泛化性能较弱的学习器构建出很强的集成，常用的基学习器就有*决策树桩*。

## Bagging和随机森林

从前面可知，我们要给个体学习器足够但不同的数据集。为了解决这个问题，可以考虑使用**相互有交叠**的采样子集。

### Bagging

Bagging 是并行式集成学习方法的典型代表。它直接基于**自助采样法**。我们可以采样出T 个含有m 个训练样本的采样集，然后基于每个采样集训练出一个基学习器，再将这些基学习器进行结合。

在对预测输出进行结合时，Bagging 通常对分类任务使用**简单投票法**，对回归任务使用**简单平均法**。若分类预测时出现两个类收到同样票数的情形，则最简单的做法是**随机选择**一个，也可进一步考察学习器投票的**置信度**来确定最终胜者。

![幕快照 2018-03-16 16.29.1](/Users/lipenghua/Downloads/屏幕快照 2018-03-16 16.29.18.png)

假定基学习器的计算复杂度为O(m)，则Bagging 的复杂度大致为T(O(m) + O(s))。可见Bagging十分高效。且Bagging 能不经修改地用于多分类、回归任务。

自助采样过程还给 Bagging 带来了另一个优点：由于每个 基学习器只使用了初始训练集中约 63.2% 的样本，剩下约 36.8% 的样本可用作**验证集**来对泛化性能进行**包外估计**。

### 随机森林

随机森林 (Random Forest) 是Bagging 的一个扩展变体。RF 在以决策树为基学习器构建Bagging 集成的基础上，进一步在决策树的训练过程中引入了**随机属性选择**：在BF 中，对决策树的每个节点，先从该节点的属性集合中随机选择一个包含k 个属性的**子集**，然后再从这个子集中选择一个最优属性用于划分。这里的参数k 控制了**随机性的引入程度**。若令k = d，则基决策树的构建与传统决策树相同；若令k = 1，则是随机选择一个属性用于划分。推荐$k=\log_2 d$。

随机森林中基学习器的多样性不仅来自样本扰动，还来自**属性扰动**。这就使得最终集成的泛化性能可通过个体学习器之间差异度的增加而进一步提升。

![幕快照 2018-03-16 17.05.0](/Users/lipenghua/Downloads/屏幕快照 2018-03-16 17.05.06.png)

随机森林的起始性能往往相对较差，特别是在集成中只包含一个基学习器时。这很容易理解，因为通过引入属性扰动，随机森林中个体学习器的性能往往有所降低。随机森林的训练效率也会优于Bagging，因为属性划分时考察的属性集较小。

## 结合策略

### 平均法

对于数值型输出$h_i(\mathbf{x}) \in R$，最常见的结合策略就是使用*平均法* (averaging)。

- 简单平均法：

$$
H(\mathbf{x}) = \frac{1}{T} \sum_{i=1}^T h_i(\mathbf{x})
$$

- 加权平均法：

$$
H(\mathbf{x}) = \sum_{i=1}^T \omega_i h_i(\mathbf{x})
$$

**注意**：在集成学习中一般对学习器的权重施以**非负约束**。

加权平均法的权重一般是从训练数据中学习而得。现实任务中的训练样本通常不充分或存在噪声，这使得学得的权重**不完全可靠**。对于规模比较大的集成来说，要学习的权重较多，容易导致**过拟合**。

所以，在个体学习器性能相差较大时宜使用加权平均法；而在个体学习器性能相近时宜食用简单平均法。

### 投票法

对分类任务来说，学习器hi 将从类别标记集合$\{c_1, c_2, \ldots, c_N\}$ 中预测出一个标记。最常见的是使用**投票法** (voting)。设hi 在样本x 上的预测输出为一个N 维向量$(h_i^1(\mathbf{x}),;h_i^2(\mathbf{x}); \ldots,;h_i^N(\mathbf{x}))$。

- 绝对多数投票法：某标记得票超过半数，则预测为该标记；否则拒绝预测。

$$
H(\mathbf{x})=
\begin{cases}
c_j,\ if \sum_{i=1}^T h_i^j(\mathbf{x}) > 0.5 \sum_{k=1}^N\sum_{i=1}^T h_i^k(\mathbf{x}) \\
reject,\ otherwise
\end{cases}
$$

- 相对多数投票法：预测为得票最多的标记，若同时有多个标记获最高票，则从中随机选取。

$$
H(\mathbf{x})=c_{\arg\max_j \sum_{i=1}^T h_i^j(\mathbf{x})}
$$

- 加权投票法：

$$
H(\mathbf{x})=c_{\arg\max_j \sum_{i=1}^T \omega_i h_i^j(\mathbf{x})}
$$

现实任务中，不同类型的个体学习器可能产生**不同类型**的h 值，常见的有：

- 类标记：$h_i^j(\mathbf{x}) \in \{0, 1\}$，即预测类别标记为1，称为*硬投票*；
- 类概率：$h_i^j(\mathbf{x}) \in [0,1]$，相当于对后验概率$P(c_j|\mathbf{x})$ 的一个估计，称为*软投票*。

### 学习法

当训练数据很多时，一种更为强大的结合策略是使用*学习法*，即通过**另一个学习器**来进行结合。Stacking 是学习法的代表。此时，个体学习器称为**初级学习器**，用于结合的学习器称为**次级学习器**或**元学习器** (meta-learner)。

**流程**：Stacking 先从初始数据集中训练出初级学习器，然后“生成”一个新数据集用于训练次级学习器。在新数据集中，初级学习器的输出被当作样例输入特征，而初始样本的标记仍被当作杨例标记。

![幕快照 2018-03-16 20.51.4](../../../../../Downloads/屏幕快照 2018-03-16 20.51.45.png)

**问题**：次级学习器是利用初级学习器产生的，若**直接使用**初级学习器的训练集来生成次级训练集，**过拟合**风险比较大。

**解决**：采用*交叉验证*获*留一法*，用未被初级学习器使用的样本来产生次级学习器的训练样本。

次级学习器的**输入属性表示**和**次级学习算法**对Stacking 集成的泛化性能都有很大影响。**贝叶斯模型平均** (Baues Model Averaging, RMA) 基于后验概率来为不同模型赋予权重，可以视为加权平均法的一种特殊实现。